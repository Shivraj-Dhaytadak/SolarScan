{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.document_loaders.generic import GenericLoader\n",
    "from langchain.document_loaders.parsers import LanguageParser\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter , Language\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain_ollama.embeddings import OllamaEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "repo_path = \"C:\\VScodeMaster\\GeminiAPI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "loader = GenericLoader.from_filesystem(repo_path,\n",
    "                                        glob = \"**/*\",\n",
    "                                       suffixes=[\".py\"],\n",
    "                                       show_progress=True,\n",
    "                                       parser = LanguageParser(language=Language.PYTHON, parser_threshold=500)\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e138b5c18c244f84a79990bb70ff92e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "documents = loader.load()\n",
    "chunks = RecursiveCharacterTextSplitter.from_language(Language.PYTHON,chunk_size = 2000,\n",
    "                                                             chunk_overlap = 200).split_documents(documents=documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings(model=\"qwen2.5-coder:7b\",)\n",
    "# LLM \n",
    "llm = ChatOllama(model='qwen2.5-coder:7b',keep_alive='2h',num_predict = 90000)\n",
    "\n",
    "memory = ConversationSummaryMemory(llm=llm, memory_key = \"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./chroma'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordb = Chroma.from_documents(chunks, embedding=embeddings) # , persist_directory='./db' for the persistent storage\n",
    "vectordb._persist_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"\n",
    "Youre a software engineer and you have to explain the given code based on the context from retrieved documents.\n",
    "Explain every thing in a detailed manner like youre having a Knowledge Transfer session with a colleague.\n",
    "Things you need to do give explanation of the code start from classes and their methods and working and so on. DO NOT SUMMARIZE.\n",
    "explain each function in detail and how it works and what it does. if asked only a function explain that function only with reference to the file it is used.\n",
    "DO NOT SUMMARIZE.\n",
    "context: {context}\n",
    "Question:{input}\n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(PROMPT)\n",
    "\n",
    "stuff_chain = create_stuff_documents_chain(llm=llm,prompt=prompt, output_parser=StrOutputParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_chain = create_retrieval_chain(retriever=vectordb.as_retriever(),combine_docs_chain=stuff_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Let's break down the provided codebase step by step. This code is a FastAPI application that handles chat-related operations, including creating, retrieving, and deleting chats.\n",
      "\n",
      "### **1. FastAPI Setup**\n",
      "\n",
      "First, we have the FastAPI setup with some imports:\n",
      "\n",
      "```python\n",
      "from fastapi import FastAPI\n",
      "import models\n",
      "from dotenv import load_dotenv\n",
      "from database import sql_engine\n",
      "from repo import Userrepo\n",
      "from routers import User, Chat, authentication\n",
      "```\n",
      "\n",
      "- **FastAPI**: The main framework for building API.\n",
      "- **models**: This module contains SQLAlchemy models that define the structure of the database tables.\n",
      "- **dotenv**: A Python library used to load environment variables from a `.env` file.\n",
      "- **sql_engine**: An instance of an SQL engine created using SQLAlchemy, which is used to connect to the database.\n",
      "- **Userrepo**: Repository for handling user-related operations (likely in `repo/user.py`).\n",
      "- **authentication**: Router for authentication-related endpoints (likely in `routers/authentication.py`).\n",
      "- **User** and **Chat**: Routers for handling user and chat-related operations (likely in `routers/User.py` and `routers/Chat.py`, respectively).\n",
      "\n",
      "### **2. Loading Environment Variables**\n",
      "\n",
      "```python\n",
      "load_dotenv()\n",
      "```\n",
      "\n",
      "This line loads environment variables from a `.env` file, typically used to store sensitive information like database credentials.\n",
      "\n",
      "### **3. Creating the FastAPI App Instance**\n",
      "\n",
      "```python\n",
      "app = FastAPI()\n",
      "```\n",
      "\n",
      "Here we create an instance of the `FastAPI` class. This app will handle incoming HTTP requests and route them to appropriate endpoints.\n",
      "\n",
      "### **4. Database Table Creation**\n",
      "\n",
      "```python\n",
      "models.Base.metadata.create_all(bind=sql_engine)\n",
      "```\n",
      "\n",
      "This line creates all tables defined in the SQLAlchemy models using the provided SQL engine. The `create_all` method ensures that the necessary database schema is set up according to the model definitions.\n",
      "\n",
      "### **5. Including Routers**\n",
      "\n",
      "```python\n",
      "app.include_router(authentication.router)\n",
      "app.include_router(User.router)\n",
      "app.include_router(Chat.router)\n",
      "```\n",
      "\n",
      "The `include_router` method adds the routes defined in the provided routers (`authentication`, `User`, and `Chat`) to the main app. Each router contains a set of endpoints that handle specific types of requests.\n",
      "\n",
      "### **6. Chat Router**\n",
      "\n",
      "Now, let's focus on the `Chat` router:\n",
      "\n",
      "```python\n",
      "from fastapi import APIRouter\n",
      "from sqlalchemy.orm import session\n",
      "from fastapi import APIRouter, Depends, status\n",
      "import database\n",
      "from repo import Chatrepo\n",
      "from oauth2 import get_current_user\n",
      "from schemas import *\n",
      "router = APIRouter(\n",
      "    prefix=\"\",\n",
      "    tags=['Chat']\n",
      ")\n",
      "\n",
      "get_db = database.get_db\n",
      "\n",
      "@router.get('/chats' , response_model=List[ChatBotInteractResponseSchema] , summary= \"get chat \" , status_code=status.HTTP_200_OK)\n",
      "async def get_chat_bot_chat(db : session = Depends(get_db),current_user : ChatBotUserSchema = Depends(get_current_user)):\n",
      "    return Chatrepo.get_chat_bot_chat(db)\n",
      "\n",
      "@router.get('/get_chat/{id}' , response_model=ChatBotInteractResponseSchema , summary= \"get chat \" , status_code=status.HTTP_200_OK)\n",
      "async def get_chat_bot_chat(id : int ,db : session = Depends(get_db)):\n",
      "    return Chatrepo.get_chat_bot_chat_by_id(id,db)\n",
      "\n",
      "@router.post('/new_chat/qwen',response_model=ChatBotInteractResponseSchema , description=\"Create a new chat \",summary=\"Create a new chat\",status_code=status.HTTP_201_CREATED)\n",
      "async def chat_bot_new_chat(chat: ChatBotInteractSchema ,db : session = Depends(get_db)):\n",
      "    return Chatrepo.chat_bot_new_chat(chat,db)\n",
      "\n",
      "@router.post('/new_chat/gemini',response_model=ChatBotInteractResponseSchema , description=\"Create a new chat \",summary=\"Create a new chat\",status_code=status.HTTP_201_CREATED)\n",
      "async def chat_bot_new_chat_gemini(chat: ChatBotInteractSchema ,db : session = Depends(get_db)):\n",
      "    return Chatrepo.chat_bot_new_chat_gemini(chat,db)\n",
      "\n",
      "@router.delete('/delete/{id}',status_code=status.HTTP_204_NO_CONTENT)\n",
      "async def delete_chat_bot_chat(id : int , db : session = Depends(get_db)):\n",
      "    return Chatrepo.delete_chat_bot_chat(id,db)\n",
      "```\n",
      "\n",
      "#### **6.1 Router Setup**\n",
      "\n",
      "```python\n",
      "router = APIRouter(\n",
      "    prefix=\"\",\n",
      "    tags=['Chat']\n",
      ")\n",
      "```\n",
      "\n",
      "- **prefix** is an optional string that will be prepended to all paths in the router.\n",
      "- **tags** is used for grouping endpoints in the Swagger UI.\n",
      "\n",
      "#### **6.2 Dependency Injection**\n",
      "\n",
      "```python\n",
      "get_db = database.get_db\n",
      "```\n",
      "\n",
      "This line defines a dependency injection function `get_db` that provides a SQLAlchemy session (`session`) for each request. This session is automatically closed after handling the request.\n",
      "\n",
      "### **6.3 Endpoints**\n",
      "\n",
      "- **GET /chats**:\n",
      "  - Retrieves a list of chats.\n",
      "  - Uses `response_model=List[ChatBotInteractResponseSchema]` to specify that the response should be a list of `ChatBotInteractResponseSchema` objects.\n",
      "  - Requires authentication (`current_user: ChatBotUserSchema = Depends(get_current_user)`).\n",
      "\n",
      "- **GET /get_chat/{id}**:\n",
      "  - Retrieves a specific chat by ID.\n",
      "  - Uses the same response model and authentication dependency as above.\n",
      "\n",
      "- **POST /new_chat/qwen**:\n",
      "  - Creates a new chat with the `qwen` service.\n",
      "  - Requires a JSON body (`chat: ChatBotInteractSchema`) to define the chat details.\n",
      "  - Returns the created chat with the specified response model.\n",
      "\n",
      "- **POST /new_chat/gemini**:\n",
      "  - Similar to `/new_chat/qwen`, but creates a new chat with the `gemini` service.\n",
      "\n",
      "- **DELETE /delete/{id}**:\n",
      "  - Deletes an existing chat by ID.\n",
      "  - Returns a status code of 204 (No Content) upon successful deletion.\n",
      "\n",
      "### **7. Conclusion**\n",
      "\n",
      "This FastAPI application provides endpoints for handling chat-related operations, including retrieval, creation, and deletion. It uses dependency injection to manage database sessions and includes authentication for certain endpoints. The routes are grouped under the `Chat` tag in the Swagger UI for better organization."
     ]
    }
   ],
   "source": [
    "for i in retrieval_chain.stream({\"input\": \"\"\"explain the code base in detail please \"\"\"}):\n",
    "    try:\n",
    "        if i['answer']:\n",
    "            print(i['answer'], end=\"\",flush=True)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
